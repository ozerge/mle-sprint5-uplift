{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a53fd23d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uplift AUC: 0.07\n",
      "Qini AUC: 0.09\n"
     ]
    }
   ],
   "source": [
    "# Обучение алгоритма R-learner\n",
    "# Рассмотрим пример на данных Яндекс Такси. Что нужно сделать:\n",
    "#   1. Построить предсказания out-of-fold для propensity score e(x) (вероятности попадания в группу воздействия).\n",
    "#   2. Построить предсказания out-of-fold для таргета m(x) (без влияния воздействия).\n",
    "#   3. Сформировать целевую переменную для R-learner.\n",
    "#   4. Обучить финальную uplift-модель, минимизируя R-loss.\n",
    "# \n",
    "# Задание 3\n",
    "# Запустите код ниже. Рассчитайте метрики uplift AUC и Qini AUC для предсказаний алгоритма R-learner. \n",
    "#  Не забудьте применить метод squeeze(). Выведите значения метрик с точностью до двух знаков после запятой. \n",
    "# Используйте данные А/Б теста как и ранее.\n",
    "\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from xgboost import XGBRegressor, XGBClassifier\n",
    "from sklift.metrics import uplift_auc_score, qini_auc_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"ab_results.csv\")\n",
    "\n",
    "# Подготовка данных\n",
    "features = data.drop(columns=['target','treatment']).columns\n",
    "X = data[features].values\n",
    "T = data.treatment.values  # 1 - группа воздействия, 0 - контрольная группа\n",
    "y = data.target.values  # целевая переменная\n",
    "\n",
    "# Создание фолдов для кросс-валидации\n",
    "n_splits = 4\n",
    "kf = KFold(n_splits=n_splits, shuffle=True, random_state=42)\n",
    "\n",
    "# Получение предсказаний вне фолдов для e(x) (propensity score) и m(x) (базовый исход)\n",
    "e_x = np.zeros(len(X))\n",
    "m_x = np.zeros(len(X))\n",
    "\n",
    "for train_idx, val_idx in kf.split(X):\n",
    "    # Модель для e(x): вероятность назначения воздействия\n",
    "    model_e = XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model_e.fit(X[train_idx], T[train_idx])\n",
    "    e_x[val_idx] = model_e.predict_proba(X[val_idx])[:, 1]\n",
    "    \n",
    "    # Модель для m(x): предсказание исхода\n",
    "    model_m = XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    "    model_m.fit(X[train_idx], y[train_idx])\n",
    "    m_x[val_idx] = model_m.predict(X[val_idx])\n",
    "\n",
    "# Расчет целевой переменной для R-learner\n",
    "r_target = y - m_x\n",
    "r_treat = T - e_x\n",
    "\n",
    "# Обучение финальной модели tau(x) (uplift-модель)\n",
    "# Используем XGBoost-регрессию с весами sample_weight = r_treat**2\n",
    "mask = np.abs(r_treat) > 1e-1\n",
    "X_tau = X[mask]\n",
    "r_target_tau = r_target[mask]\n",
    "r_treat_tau = r_treat[mask]\n",
    "\n",
    "tau_model = XGBRegressor(\n",
    "    n_estimators=300,\n",
    "    learning_rate=0.01,\n",
    "    max_depth=6,\n",
    "    random_state=42,\n",
    "    verbosity=0\n",
    ")\n",
    "tau_model.fit(X_tau, r_target_tau, sample_weight=(r_treat_tau**2))\n",
    "\n",
    "# Получение предсказаний uplift\n",
    "uplift_scores = tau_model.predict(X)\n",
    "\n",
    "# Расчет метрик\n",
    "uplift_auc = uplift_auc_score(y, uplift_scores.squeeze(), T)\n",
    "qini_auc = qini_auc_score(y, uplift_scores.squeeze(), T)\n",
    "\n",
    "print(f\"Uplift AUC: {uplift_auc:.2f}\")\n",
    "print(f\"Qini AUC: {qini_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "raw",
   "id": "ecfda3bb",
   "metadata": {
    "vscode": {
     "languageId": "raw"
    }
   },
   "source": [
    "Для успешной работы R-learner (с учётом его чувствительности к качеству данных и сложности настройки) необходимы:\n",
    "    - Точная оценка propensity score — здесь даже небольшие ошибки могут значительно ухудшить качество финальной модели.\n",
    "    - Качественная базовая outcome-модель — модель должна хорошо предсказывать исход без учёта воздействия, особенно при сильных нелинейных зависимостях.\n",
    "    - Достаточный объём данных — R-learner обучает три модели (propensity, outcome и effect), поэтому требует больше данных для стабильной работы.\n",
    "    - Правильный выбор базовых алгоритмов — не все алгоритмы одинаково хорошо подходят для оценки эффекта воздействия.\n",
    "    - Корректная обработка выбросов и пропущенных значений — R-learner особенно чувствителен к качеству входных данных."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b55eef35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-learner Uplift AUC: 0.16\n",
      "R-learner Qini AUC: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Задание 5\n",
    "# Пора обучать R-learner с помощью библиотеки causalml. Ваша задача — определить переменные метода fit(), где:\n",
    "# X — матрица признаков в обучающей выборке,\n",
    "# treatment — факт воздействия в обучающей выборке,\n",
    "# y — целевая переменная в обучающей выборке,\n",
    "# p — оценки propensity score для обучающей выборки.\n",
    "# Также следует прогнозы алгоритма на тестовой выборке без учёта столбца treatment.\n",
    "# Мы предварительно разделили выборку на обучающую и тестовую:\n",
    "# X_train — матрица признаков обучающей выборки,\n",
    "# T — факт воздействия в обучающей выборке (бинарная переменная),\n",
    "# y_train — целевая переменная в обучающей выборке (бинарная переменная).\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from causalml.inference.meta import BaseRClassifier\n",
    "from xgboost import XGBClassifier, XGBRegressor\n",
    "from sklift.metrics import uplift_auc_score, qini_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "data = pd.read_csv(\"ab_results.csv\")\n",
    "\n",
    "X = data.drop(['target'], axis=1)  \n",
    "y = data['target']  \n",
    "\n",
    "# разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                    stratify=data[['target', 'treatment']],\n",
    "                                    random_state=42)\n",
    "\n",
    "features = data.drop(columns=['target','treatment']).columns\n",
    "T = X_train.treatment.values  # 1 - treatment, 0 - control\n",
    "X_train = X_train[features]\n",
    "y_train = y_train.values  # целевая переменная\n",
    "T_test = X_test.treatment.values\n",
    "\n",
    "\n",
    "# инициализируем R-learner с моделями XGBoost\n",
    "# outcome_learner — модель для предсказания исхода без учёта воздействия\n",
    "# effect_learner — модель для оценки эффекта воздействия\n",
    "# propensity_learner — модель для оценки вероятности получения воздействия\n",
    "r_learner = BaseRClassifier(\n",
    "    outcome_learner=XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    effect_learner=XGBRegressor(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.01,\n",
    "        max_depth=6,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    propensity_learner=XGBClassifier(\n",
    "        n_estimators=200,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    ")\n",
    "\n",
    "# инициализируем массив для propensity score\n",
    "e_x = np.zeros(len(X_train))\n",
    "T_test = X_test.treatment.values\n",
    "\n",
    "# обучаем модель для оценки propensity score\n",
    "model_e = XGBClassifier(n_estimators=100, \n",
    "                        learning_rate=0.02, \n",
    "                        max_depth=3, \n",
    "                        random_state=42, \n",
    "                        verbosity=0)\n",
    "model_e.fit(X_train, T)\n",
    "e_x = model_e.predict_proba(X_train)[:, 1]\n",
    "\n",
    "# обучаем модель R-learner\n",
    "r_learner.fit(\n",
    "    X=X_train,\n",
    "    treatment=T,\n",
    "    y=y_train,\n",
    "    p=e_x,\n",
    "    verbose=True\n",
    ")\n",
    "\n",
    "# получаем оценки uplift-эффекта для тестовой выборки\n",
    "uplift_scores = r_learner.predict(X_test.drop(columns=['treatment']).values)\n",
    "\n",
    "# рассчитываем метрики качества модели\n",
    "uplift_auc = uplift_auc_score(y_test, uplift_scores.squeeze(), T_test)\n",
    "qini_auc = qini_auc_score(y_test, uplift_scores.squeeze(), T_test)\n",
    "\n",
    "# выводим результаты\n",
    "print(f\"R-learner Uplift AUC: {uplift_auc:.2f}\")\n",
    "print(f\"R-learner Qini AUC: {qini_auc:.2f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "048ad492",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ROC_AUC на тестовой выборке равен 0.56\n"
     ]
    }
   ],
   "source": [
    "# Задание 7\n",
    "# Обучите propensity_model (модель вероятности назначения воздействия) с помощью XGBClassifier из библиотеки xgboost. \n",
    "# Также сделайте прогноз propensity score для обучающей и тестовой выборок с помощью метода predict_proba.\n",
    "# В качестве T_train и T_test возьмите столбец воздействия (treatment) для обучающей и тестовой выборки соответственно. \n",
    "# Переопределите X_train и X_test без столбцов conversion и treatment. Используйте данные Яндекс.Плюса как и ранее.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "data = pd.read_csv(\"yandex_plus.csv\")\n",
    "\n",
    "# Разделим данные на признаки и целевую переменную\n",
    "X = data.drop(['conversion'], axis=1)  \n",
    "y = data['conversion']  \n",
    "\n",
    "treatment_mapping = {\n",
    "    'control': 0,  # 0 соответствует контрольной группе\n",
    "    'treatment1': 1  # 1 соответствует группе воздействия\n",
    "}\n",
    "\n",
    "X['treatment'] = X['treatment'].map(treatment_mapping)\n",
    "\n",
    "# разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                    stratify=data[['conversion', 'treatment']],\n",
    "                                    random_state=42)\n",
    "\n",
    "features = data.drop(columns=['conversion','treatment']).columns\n",
    "T_train = X_train.treatment.values  # 1 - treatment, 0 - control\n",
    "X_train = X_train[features]\n",
    "y_train = y_train.values  # целевая переменная\n",
    "T_test = X_test.treatment.values\n",
    "X_test = X_test[features]\n",
    "\n",
    "\n",
    "model_e = XGBClassifier(n_estimators=300, \n",
    "                        learning_rate=0.1, \n",
    "                        max_depth=4, \n",
    "                        random_state=42, \n",
    "                        verbosity=0)\n",
    "\n",
    "model_e.fit(X_train, T_train)\n",
    "# получаем propensity score для train и test\n",
    "p_train = model_e.predict_proba(X_train.values)[:, 1]\n",
    "p_test = model_e.predict_proba(X_test.values)[:, 1]\n",
    "\n",
    "roc_auc_test = roc_auc_score(y_test, p_test)\n",
    "\n",
    "print(\"ROC_AUC на тестовой выборке равен\", round(roc_auc_test, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b189f4c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R-learner Uplift AUC: 0.42\n",
      "R-learner Qini AUC: 0.37\n"
     ]
    }
   ],
   "source": [
    "# Задание 9\n",
    "# Обучите R-learner для бизнес-кейса Яндекс Плюс с помощью библиотеки causalml. Для этого:\n",
    "#   Импортируйте необходимые классы:\n",
    "#       BaseRClassifier из causalml.inference.meta, \n",
    "#       XGBClassifier и XGBRegressor из xgboost.\n",
    "#   Создайте R-learner:\n",
    "#       используйте BaseRClassifier,\n",
    "#       укажите outcome_learner,\n",
    "#       укажите effect_learner,\n",
    "#       установите control_name=0.\n",
    "#   Обучите модель:\n",
    "#       используйте метод fit(),\n",
    "#       передайте обучающую выборку, данные о воздействии, таргет обучающей выборки, \n",
    "#           propensity score из предыдущего задания для обучающей выборки (p_train).\n",
    "# \n",
    "# Не забудьте про random_state=42 для воспроизводимости экспериментов.\n",
    "\n",
    "N_ESTIMATORS = 50 \n",
    "LEARNING_RATE = 0.005 \n",
    "MAX_DEPTH = 6\n",
    "\n",
    "\n",
    "r_learner = BaseRClassifier(\n",
    "    outcome_learner=XGBClassifier(\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    effect_learner=XGBRegressor(\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    ),\n",
    "    propensity_learner=XGBClassifier(\n",
    "        n_estimators=N_ESTIMATORS,\n",
    "        learning_rate=LEARNING_RATE,\n",
    "        max_depth=MAX_DEPTH,\n",
    "        random_state=42,\n",
    "        verbosity=0\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "# Обучите R-learner на обучающей выборке\n",
    "r_learner.fit(\n",
    "    X=X_train,\n",
    "    treatment=T_train,\n",
    "    y=y_train,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "# Получаем оценки uplift эффекта для тестовой выборки\n",
    "uplift_scores = r_learner.predict(X_test[features].values)\n",
    "\n",
    "# Рассчитываем метрики качества модели\n",
    "uplift_auc = uplift_auc_score(y_test, uplift_scores.squeeze(), T_test)\n",
    "qini_auc = qini_auc_score(y_test, uplift_scores.squeeze(), T_test)\n",
    "\n",
    "# Выводим результаты\n",
    "print(f\"R-learner Uplift AUC: {uplift_auc:.2f}\")\n",
    "print(f\"R-learner Qini AUC: {qini_auc:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".uplift_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
