{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8519a0d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-sprint5-uplift/.uplift_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uplift AUC: 0.13\n",
      "Qini AUC: 0.16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/mle-user/mle_projects/mle-sprint5-uplift/.uplift_env/lib/python3.10/site-packages/sklearn/linear_model/_logistic.py:470: ConvergenceWarning: lbfgs failed to converge after 1000 iteration(s) (status=1):\n",
      "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT\n",
      "\n",
      "Increase the number of iterations to improve the convergence (max_iter=1000).\n",
      "You might also want to scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    }
   ],
   "source": [
    "# Задание 2\n",
    "# Обучите T-learner c помощью двух логистических регрессий (LogisticRegression). \n",
    "# Для этого вам потребуются данные А/Б теста.\n",
    "\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklift.metrics import uplift_auc_score, qini_auc_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "data = pd.read_csv(\"ab_results.csv\")\n",
    "\n",
    "# разделим данные на признаки и целевую переменную\n",
    "X = data.drop(['target'], axis=1)  # все столбцы, кроме целевой переменной\n",
    "y = data['target']  # целевая переменная (например, количество поездок)\n",
    "\n",
    "# разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                    stratify=data[['target', 'treatment']],\n",
    "                                    random_state=42)\n",
    "\n",
    "# разделяем обучающую выборку на treatment=1 и treatment=0\n",
    "X_train_treat = X_train[X_train['treatment'] == 1].drop('treatment', axis=1)\n",
    "y_train_treat = y_train[X_train['treatment'] == 1]\n",
    "\n",
    "X_train_control = X_train[X_train['treatment'] == 0].drop('treatment', axis=1)\n",
    "y_train_control = y_train[X_train['treatment'] == 0]\n",
    "\n",
    "# создаём две логистические регрессии\n",
    "t_learner_1 = LogisticRegression(random_state=1, max_iter=1000)\n",
    "t_learner_0 = LogisticRegression(random_state=1, max_iter=1000)\n",
    "\n",
    "# обучаем модели\n",
    "t_learner_1.fit(X_train_treat, y_train_treat)\n",
    "t_learner_0.fit(X_train_control, y_train_control)\n",
    "\n",
    "\n",
    "# применяем обе модели к тестовой выборке (без признака 'treatment')\n",
    "X_test_features = X_test.drop('treatment', axis=1)\n",
    "df_test = X_test.copy()\n",
    "df_test['yes_treatment'] = t_learner_1.predict_proba(X_test_features)[:, 1]\n",
    "df_test['no_treatment'] = t_learner_0.predict_proba(X_test_features)[:, 1]\n",
    "\n",
    "# расчёт uplift\n",
    "uplift_vals = df_test['yes_treatment'] - df_test['no_treatment']\n",
    "df_test['uplift_score'] = uplift_vals\n",
    "\n",
    "# метрики uplift score и qini score\n",
    "uplift_score = uplift_auc_score(y_test.values, uplift_vals.values, X_test['treatment'].values)\n",
    "qini_score = qini_auc_score(y_test.values, uplift_vals.values, X_test['treatment'].values)\n",
    "\n",
    "print(f\"Uplift AUC: {uplift_score:.2f}\")\n",
    "print(f\"Qini AUC: {qini_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5195d71c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uplift AUC: 0.16\n",
      "Qini AUC: 0.20\n"
     ]
    }
   ],
   "source": [
    "# Здесь всё очень похоже на обучение S-learner: вы также используете базовую модель (например, RandomForestClassifier или логистическую регрессию), \n",
    "# но обучаете две независимые — одну только на данных с treatment=1 (группа воздействия), а вторую — только на данных с treatment=0 (контрольная группа). \n",
    "# В библиотеке causalml есть класс BaseTClassifier, который реализует T-learner для различных моделей. \n",
    "# После обучения обеих моделей вы получаете uplift для каждого пользователя как разницу между предсказаниями этих моделей.\n",
    "# \n",
    "# Задание 4\n",
    "# Посмотрим на код обучения T-learner с помощью случайного леса из библиотеки causalml. \n",
    "\n",
    "from causalml.inference.meta import BaseTClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklift.metrics import uplift_auc_score, qini_auc_score\n",
    "\n",
    "# создаём базовые модели для тестовой и контрольной групп \n",
    "treatment_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "control_model = RandomForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=6,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# инициализируем T-learner\n",
    "t_learner = BaseTClassifier(\n",
    "    treatment_learner=treatment_model,\n",
    "    control_learner=control_model,\n",
    "    control_name=0,  # название контрольной группы в столбце treatment\n",
    ")\n",
    "\n",
    "# обучаем T-learner\n",
    "# примечание: X_train должен иметь столбец 'treatment' со значениями 'treatment' и 'control'\n",
    "t_learner.fit(\n",
    "    X=X_train.values,  # Признаки без столбца treatment\n",
    "    treatment=X_train['treatment'].values,       # Столбец с признаком воздействия\n",
    "    y=y_train.values                            # Целевая переменная\n",
    ")\n",
    "\n",
    "# получаем предсказания для тестовой выборки\n",
    "uplift_pred = t_learner.predict(X_test.values)\n",
    "\n",
    "# рассчитываем метрики uplift\n",
    "uplift_score = uplift_auc_score(\n",
    "    y_test.values, \n",
    "    uplift_pred.squeeze(), \n",
    "    X_test['treatment'].values\n",
    ")\n",
    "qini_score = qini_auc_score(\n",
    "    y_test.values, \n",
    "    uplift_pred.squeeze(), \n",
    "    X_test['treatment'].values\n",
    ")\n",
    "\n",
    "print(f\"Uplift AUC: {uplift_score:.2f}\")\n",
    "print(f\"Qini AUC: {qini_score:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "010eb9a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uplift AUC: 0.24\n",
      "Qini AUC: 0.17\n"
     ]
    }
   ],
   "source": [
    "# Задание 6\n",
    "# Ваша задача — реализовать T-learner и получить показатели не хуже, чем у S-learner: uplift score не ниже 0.20 и Qini score не ниже 0.15. \n",
    "# Датасет уже был разделен на обучающую и тестовую выборки: \n",
    "#   X_train, y_train — обучающая выборка;\n",
    "#   X_test, y_test — тестовая выборка;\n",
    "# В X_train и X_test есть столбец treatment, который указывает, получил ли пользователь скидку (1) или нет (0).\n",
    "# Вы можете использовать любой из изученных подходов (например, RandomForestClassifier, LogisticRegression, UpliftRandomForestClassifier, CatBoostClassifier, BaseTClassifier). \n",
    "# Главное — достичь требуемого качества. Пробуйте различные модели и комбинации гиперпараметров.\n",
    "# Реализуйте обучение двух отдельных моделей: одну для treatment-группы (получивших скидку), другую — для control-группы (без скидки). \n",
    "# Затем рассчитайте uplift для тестовой выборки и выведите значения метрик uplift AUC и Qini AUC. \n",
    "# Чтобы было проще, используйте библиотеку causalml. \n",
    "# Но если хочется реализовать алгоритм «вручную» — мы не против! Данные можно скачать здесь.\n",
    "\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from causalml.inference.meta import BaseTClassifier\n",
    "from sklift.metrics import uplift_auc_score, qini_auc_score\n",
    "\n",
    "# загрузка данных\n",
    "data = pd.read_csv(\"yandex_plus.csv\")\n",
    "\n",
    "# разделим данные на признаки и целевую переменную\n",
    "X = data.drop(['conversion'], axis=1)  \n",
    "y = data['conversion']  \n",
    "\n",
    "# применяем маппинг для удобства обучения модели\n",
    "treatment_mapping = {\n",
    "    'control': 0,  # 0 соответствует контрольной группе\n",
    "    'treatment1': 1  # 1 соответствует группе воздействия\n",
    "}\n",
    "\n",
    "X['treatment'] = X['treatment'].map(treatment_mapping)\n",
    "\n",
    "# разделим данные на обучающую и тестовую выборки\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, \n",
    "                                    stratify=data[['conversion', 'treatment']],\n",
    "                                    random_state=42)\n",
    "\n",
    "# создаём базовые модели для тестовой и контрольной групп \n",
    "treatment_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "control_model = RandomForestClassifier(\n",
    "    n_estimators=200,\n",
    "    max_depth=8,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "# инициализируем T-learner\n",
    "t_learner = BaseTClassifier(\n",
    "    treatment_learner=treatment_model,\n",
    "    control_learner=control_model,\n",
    "    control_name=0,  # название контрольной группы в столбце treatment\n",
    ")\n",
    "\n",
    "# обучаем T-learner\n",
    "# примечание: X_train должен иметь столбец treatment со значениями treatment и control\n",
    "t_learner.fit(\n",
    "    X=X_train.values,  \n",
    "    treatment=X_train['treatment'].values,       # Столбец с признаком воздействия\n",
    "    y=y_train.values                            # Целевая переменная\n",
    ")\n",
    "\n",
    "# получаем предсказания для тестовой выборки\n",
    "uplift_pred = t_learner.predict(X_test.values)\n",
    "\n",
    "# рассчитываем метрики uplift\n",
    "uplift_score = uplift_auc_score(\n",
    "    y_test.values, \n",
    "    uplift_pred.squeeze(), \n",
    "    X_test['treatment'].values\n",
    ")\n",
    "qini_score = qini_auc_score(\n",
    "    y_test.values, \n",
    "    uplift_pred.squeeze(), \n",
    "    X_test['treatment'].values\n",
    ")\n",
    "\n",
    "print(f\"Uplift AUC: {uplift_score:.2f}\")\n",
    "print(f\"Qini AUC: {qini_score:.2f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".uplift_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
